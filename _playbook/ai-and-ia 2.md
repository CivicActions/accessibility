---
layout: playbook
title: Consider AI & IA
description: 
excerpt: 
sidenav: docs
categories:
  - Accessibility

---

Artificial Intelligence (AI) is already being used in places to help people with disabilities. It has provided very useful as a means to include people with hearing loss in Google Meet, Microsoft Teams and now Zoom meetings, as well. There are many applications which are proving useful for people who are blind, low vision or those who are color blind. There are ways that it could be used to support people with all forms of disability.

On the other hand, there are a lot of AI projects which are making bold claims which exaggerate what they can actually do, and where it is possible to actually hurt people with disabilities. A popular example is the [AccessiBe](https://adrianroselli.com/2020/06/accessibe-will-get-you-sued.html?Theme=Light) widget that boldly claims to use AI to make your website WCAG 2.1 AA compliant, while failing to do so. AI Image recognition for alt text is another example, where people are hoping to simply replace the human effort of writing a meaningful alt text. 

[Jutta Treviranus](https://medium.com/@MITIBMLab/will-ai-methods-treat-people-with-disabilities-fairly-7626b38f9cb5) has pioneered many important inclusion initiatives, and her work on AI is no exception. The edge cases are always going to be at a higher risk of being misunderstood while using machine learning. We need to shift our design approaches from [merely satisfying 80%](https://medium.com/ontariodigital/if-you-want-the-best-design-ask-strangers-to-help-e37bdb73567) of the users, to build for the fringe. As with other minorities groups, people with disabilities are often disadvantaged with biased data. 

We can use machine learning to support accessibility, but in many cases it is better to approach it from the approach of Intelligence Augmented (IA). How do we use AI to support authors to produce better content. Perhaps it is by suggesting alt text for the author to review and modify (if needed). AI can also look for patterns in larger datasets than people can process to look for errors that a human would find difficult to pick out. 

## Key questions

* What algorithms are you using in your organization?
* Have those been assessed for bias?
